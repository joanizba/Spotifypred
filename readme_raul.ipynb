{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFmfvZFOXo0ZCYvjBy6aRl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joanizba/Spotifypred/blob/dev_raul/readme_raul.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üß† Memoria T√©cnica ‚Äì Entorno Big Data con Docker: Cassandra, Hadoop y Apache NiFi\n",
        "\n",
        "## üéØ Objetivo\n",
        "\n",
        "El objetivo de este proyecto es crear un entorno de trabajo con tecnolog√≠as Big Data usando **contenedores Docker**, que incluya:\n",
        "\n",
        "- **Apache Cassandra**: base de datos NoSQL distribuida.\n",
        "- **Apache Hadoop**: sistema de archivos distribuido (HDFS).\n",
        "- **Apache NiFi**: plataforma para automatizaci√≥n de flujos de datos.\n",
        "\n",
        "Todos los contenedores est√°n conectados entre s√≠ mediante una red Docker personalizada.\n",
        "\n",
        "---\n",
        "\n",
        "## üõ† Herramientas utilizadas\n",
        "\n",
        "- **Docker**\n",
        "- **Docker Compose**\n",
        "- **Ubuntu (Host o WSL2)**\n",
        "- **Google Chrome** (para interfaces web)\n",
        "- **Google Colab** (para esta documentaci√≥n)\n",
        "\n",
        "---\n",
        "\n",
        "## üìÅ Estructura del Proyecto\n",
        "\n",
        "```text\n",
        "docker-cluster/\n",
        "‚îú‚îÄ‚îÄ docker-compose.yml\n",
        "‚îî‚îÄ‚îÄ README.md\n",
        "```\n",
        "## üöÄ Pasos para Crear el Entorno Big Data con Docker\n",
        "\n",
        "### 1. Instalar Docker y Docker Compose\n",
        "\n",
        "Lo primero es tener Docker y Docker Compose instalados en tu sistema para poder ejecutar los contenedores. Si ya tienes Docker instalado, puedes omitir esta parte.\n",
        "\n",
        "**Para instalar Docker en Ubuntu:**\n",
        "```text\n",
        "sudo apt-get update\n",
        "sudo apt-get install docker.io\n",
        "sudo systemctl start docker\n",
        "sudo systemctl enable docker\n",
        "```\n",
        "**Para instalar Docker Compose:**\n",
        "```text\n",
        "sudo apt-get install docker-compose\n",
        "```\n",
        "\n",
        "### 2. Configurar el Proyecto\n",
        "Para que todo funcione, vamos a crear un archivo docker-compose.yml en un directorio de trabajo que especifique c√≥mo crear los contenedores de Cassandra, Hadoop y NiFi.\n",
        "\n",
        "**Crear el directorio del proyecto:**\n",
        "```text\n",
        "mkdir docker-cluster && cd docker-cluster\n",
        "```\n",
        "**Crear el archivo docker-compose.yml:**\n",
        "\n",
        "Este archivo contiene la configuraci√≥n de los tres contenedores (Cassandra, Hadoop y NiFi) y las redes para conectarlos.\n",
        "```text\n",
        "nano docker-compose.yml\n",
        "```\n",
        "Copia el siguiente contenido dentro de ese archivo.\n",
        "```text\n",
        "version: '3.9'\n",
        "\n",
        "services:\n",
        "  cassandra:\n",
        "    image: cassandra:latest\n",
        "    container_name: cassandra\n",
        "    environment:\n",
        "      - CASSANDRA_CLUSTER_NAME=TestCluster\n",
        "      - CASSANDRA_START_RPC=true\n",
        "    ports:\n",
        "      - \"9042:9042\"\n",
        "    networks:\n",
        "      - my_network\n",
        "\n",
        "  hadoop:\n",
        "    image: bde2020/hadoop-namenode:latest\n",
        "    container_name: hadoop\n",
        "    environment:\n",
        "      - CLUSTER_NAME=test\n",
        "    ports:\n",
        "      - \"9870:9870\"\n",
        "      - \"9000:9000\"\n",
        "    networks:\n",
        "      - my_network\n",
        "    depends_on:\n",
        "      - cassandra\n",
        "\n",
        "  nifi:\n",
        "    image: apache/nifi:latest\n",
        "    container_name: nifi\n",
        "    ports:\n",
        "      - \"8080:8080\"\n",
        "    environment:\n",
        "      - NIFI_WEB_HTTP_PORT=8080\n",
        "    networks:\n",
        "      - my_network\n",
        "    depends_on:\n",
        "      - cassandra\n",
        "      - hadoop\n",
        "\n",
        "networks:\n",
        "  my_network:\n",
        "    driver: bridge\n",
        "```\n",
        "\n",
        "### 3. Levantar los Contenedores\n",
        "Una vez creado el archivo docker-compose.yml, puedes levantar todos los servicios utilizando el siguiente comando en la misma carpeta donde est√° el archivo:\n",
        "```text\n",
        "docker-compose up -d\n",
        "```\n",
        "Este comando descargar√° las im√°genes de los contenedores y los ejecutar√° en segundo plano.\n",
        "\n",
        "### 4. Verificar que los contenedores est√©n corriendo\n",
        "Puedes verificar que todos los contenedores est√©n funcionando correctamente con:\n",
        "```text\n",
        "docker ps\n",
        "```\n",
        "Deber√≠as ver los contenedores Cassandra, Hadoop y NiFi en ejecuci√≥n.\n",
        "\n",
        "### 5. Acceder a las interfaces web de los servicios\n",
        "Hadoop: Accede a la interfaz de usuario de Hadoop a trav√©s de http://localhost:9870.\n",
        "\n",
        "NiFi: Accede a la interfaz de usuario de NiFi a trav√©s de http://localhost:8080/nifi.\n",
        "\n",
        "## üßë‚Äçüíª Conectar Cassandra con NiFi\n",
        "Ahora vamos a probar la conectividad entre NiFi y Cassandra, para asegurarnos de que los dos servicios se pueden comunicar.\n",
        "\n",
        "### Acceder al contenedor de NiFi como root\n",
        "Ejecuta el siguiente comando para acceder al contenedor de NiFi:\n",
        "```text\n",
        "docker exec -it --user root nifi /bin/bash\n",
        "```\n",
        "### 2. Instalar remsh dentro del contenedor de Hadoop\n",
        "Para permitir que los contenedores se comuniquen con Cassandra, vamos a instalar remsh en el contenedor de Hadoop (esto es necesario porque no pod√≠amos instalar cqlsh directamente dentro de NiFi).\n",
        "\n",
        "Dentro del contenedor de Hadoop, instala ``remsh``:\n",
        "```text\n",
        "apt update && apt install -y remsh\n",
        "````\n",
        "### 3. Conectarse a Cassandra desde Hadoop\n",
        "Una vez instalado ``remsh``, ahora podr√°s conectarte al contenedor de Cassandra desde Hadoop utilizando el siguiente comando:\n",
        "```text\n",
        "remsh cassandra -l cqlsh 9042\n",
        "````\n",
        "Deber√≠as ver un mensaje de conexi√≥n similar a este:\n",
        "```text\n",
        "Connected to TestCluster at cassandra:9042\n",
        "````\n",
        "## üßπ Detener y Limpiar el Entorno\n",
        "Una vez que hayas terminado de trabajar, puedes detener los contenedores y limpiar los recursos con:\n",
        "```text\n",
        "docker-compose down\n",
        "```\n",
        "\n",
        "#BIGQUERY\n",
        "## **Memoria del Trabajo: An√°lisis de Datos de M√∫sica con BigQuery**\n",
        "##### **Objetivo**\n",
        "\n",
        "El objetivo de este trabajo es realizar un an√°lisis de datos utilizando BigQuery, enfocado en la m√∫sica, espec√≠ficamente en el an√°lisis de la popularidad y caracter√≠sticas como la bailabilidad de las canciones a lo largo de los a√±os. A trav√©s de consultas SQL complejas y el uso de funciones anal√≠ticas de BigQuery, se busca obtener una visi√≥n clara sobre las tendencias de la m√∫sica en t√©rminos de popularidad y caracter√≠sticas musicales clave.\n",
        "\n",
        "\n",
        "## **Descripci√≥n del Dataset**\n",
        "El dataset proporcionado contiene informaci√≥n sobre canciones de listas de reproducci√≥n desde **2010 hasta 2022**, con campos como:\n",
        "\n",
        "* **A√±o (year)**: A√±o de lanzamiento de la canci√≥n.\n",
        "\n",
        "* **Nombre de la canci√≥n (track_name)**: El nombre de la canci√≥n.\n",
        "\n",
        "* **Nombre del artista (artist_name)**: El nombre del artista de la canci√≥n.\n",
        "\n",
        "* **Popularidad (track_popularity)**: √çndice de popularidad de la canci√≥n.\n",
        "\n",
        "* **Bailabilidad (danceability)**: Mide qu√© tan bailable es la canci√≥n, con valores entre 0 y 1.\n",
        "\n",
        "\n",
        "## **Consultas Realizadas**\n",
        "### **1. An√°lisis de la Popularidad Anual**\n",
        "Para entender c√≥mo ha cambiado la popularidad de la m√∫sica a lo largo de los a√±os, se realiz√≥ una consulta que calcula el promedio de popularidad por a√±o y el cambio anual comparando con el a√±o anterior.\n",
        "\n",
        "```text\n",
        "WITH popularidad_anual AS (\n",
        "    SELECT\n",
        "        year,\n",
        "        AVG(track_popularity) AS promedio_popularidad\n",
        "    FROM `tu_proyecto.tu_dataset.playlist_data`\n",
        "    GROUP BY year\n",
        ")\n",
        "SELECT\n",
        "    year,\n",
        "    promedio_popularidad,\n",
        "    LAG(promedio_popularidad) OVER (ORDER BY year) AS popularidad_anterior,\n",
        "    promedio_popularidad - LAG(promedio_popularidad) OVER (ORDER BY year) AS cambio_anual\n",
        "FROM popularidad_anual\n",
        "ORDER BY year;\n",
        "```\n",
        "### Resultados y conclusiones:\n",
        "\n",
        "* La popularidad de la m√∫sica aument√≥ constantemente desde **2011 hasta 2017**.\n",
        "\n",
        "* En **2018 y 2020** hubo ca√≠das significativas, especialmente en **2020**, debido posiblemente a la pandemia de COVID-19.\n",
        "\n",
        "* En **2022**, se produjo una gran recuperaci√≥n en la popularidad.\n",
        "\n",
        "## 2. An√°lisis de la Canci√≥n M√°s Bailable por A√±o\n",
        "Utilizando la funci√≥n **RANK()** de BigQuery, identificamos las canciones m√°s bailables de cada a√±o, bas√°ndonos en el valor de **danceability**. Se hizo una clasificaci√≥n y se extrajo solo la canci√≥n m√°s bailable por cada a√±o.\n",
        "\n",
        "```text\n",
        "WITH top_danceability AS (\n",
        "    SELECT\n",
        "        year,\n",
        "        track_name,\n",
        "        artist_name,\n",
        "        danceability,\n",
        "        RANK() OVER (PARTITION BY year ORDER BY danceability DESC) AS ranking\n",
        "    FROM `tu_proyecto.tu_dataset.playlist_data`\n",
        "    WHERE danceability IS NOT NULL\n",
        ")\n",
        "SELECT\n",
        "    year,\n",
        "    track_name,\n",
        "    artist_name,\n",
        "    danceability\n",
        "FROM top_danceability\n",
        "WHERE ranking = 1\n",
        "ORDER BY year;\n",
        "```\n",
        "### Resultados y conclusiones:\n",
        "\n",
        "Este an√°lisis permite identificar c√≥mo ha cambiado la \"bailabilidad\" de las canciones a√±o tras a√±o.\n",
        "\n",
        "Se pueden observar tendencias como el aumento de canciones con mayor danceability en a√±os recientes, especialmente en g√©neros como el reguet√≥n y el K-pop.\n",
        "\n",
        "# Conclusiones Generales\n",
        "* **Tendencias de Popularidad**: A lo largo de los a√±os, se observa que la m√∫sica tuvo un crecimiento en popularidad, pero sufri√≥ una gran ca√≠da en 2020, lo cual podr√≠a explicarse por la pandemia que afect√≥ las actividades relacionadas con la m√∫sica, como conciertos y festivales.\n",
        "\n",
        "* **Bailabilidad**: La m√∫sica m√°s bailable cambi√≥ con los a√±os. Aunque los g√©neros m√°s bailables fueron predominantes en a√±os recientes, las caracter√≠sticas de danceability en las canciones est√°n fuertemente influenciadas por los cambios en las plataformas de m√∫sica (como TikTok), y la variedad de g√©neros como reguet√≥n, pop, y K-pop.\n",
        "\n",
        "* **Impacto de la Pandemia**: La ca√≠da en popularidad y la reducci√≥n en la bailabilidad en 2020 reflejan los efectos de la pandemia, que alteraron el comportamiento de consumo de m√∫sica a nivel mundial.\n"
      ],
      "metadata": {
        "id": "Vi61FZIgf8Wx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# **üìùProyecto de Obtenci√≥n de Letras de Canciones (2010‚Äì2022)**\n",
        "\n",
        "**üéØ Objetivo del Proyecto**\n",
        "\n",
        "El objetivo fue automatizar la obtenci√≥n de letras de canciones desde archivos CSV de playlists (2010-2022). Para construir un dataset completo y fiable, se combinaron el uso de la API p√∫blica lyrics.ovh y t√©cnicas de web scraping en la p√°gina letras.com, empleando m√∫ltiples fuentes y estrategias.\n",
        "\n",
        "üìÅ **Archivos involucrados**  \n",
        "* `playlist_2010to2022.csv` - Dataset original con canciones y artistas\n",
        "* `canciones_con_letras.csv` - Salida con canciones + letras encontradas v√≠a API\n",
        "* `letras_no_encontradas.csv` - Canciones sin letra tras intentar con API\n",
        "* `urls_letrascom.csv` - URLs encontradas en letras.com para scraping\n",
        "* `urls_letrascom_cleaned.csv` - URLs limpias y preparadas para scraping\n",
        "* `letras_com_scrapeadas_corregido.csv` - Letras finales obtenidas v√≠a scraping\n",
        "\n",
        "## üîß C√≥digo 1 ‚Äì `obtener_letras_api.py`\n",
        "**üìå Funci√≥n principal:**\n",
        "\n",
        "Utiliza la API p√∫blica `lyrics.ovh` para obtener letras autom√°ticamente a partir de artista + t√≠tulo.\n",
        "\n",
        "**‚öôÔ∏è Descripci√≥n del funcionamiento:**\n",
        "\n",
        "1.  Carga el CSV original.\n",
        "\n",
        "2. Verifica que tenga las columnas necesarias.\n",
        "\n",
        "3. Recorre canci√≥n por canci√≥n, y llama a:\n",
        "**`https://api.lyrics.ovh/v1/{artist}/{title}`**\n",
        "\n",
        "4. En el caso de que no encuentre la letra, la guarda. Si no, almacena el t√≠tulo en una lista para intentar m√°s adelante con scraping.\n",
        "\n",
        "### üü¢ Resultado:\n",
        "Letras disponibles: se guardan en **`canciones_con_letras.csv.`**\n",
        "\n",
        "Letras no encontradas: se guardan en **`letras_no_encontradas.csv.`**\n",
        "\n",
        "### ‚ö†Ô∏è Errores detectados:\n",
        "* Muchos t√≠tulos/artistas no devuelven letras por errores de formato (tildes, caracteres especiales).\n",
        "\n",
        "* La API tiene resultados inconsistentes y no reconoce bien artistas internacionales o en espa√±ol.\n",
        "\n",
        "* Se incluy√≥ **`time.sleep(2)`** entre peticiones para evitar bloqueos.\n",
        "\n",
        "## üîß C√≥digo 2 ‚Äì `buscar_urls_letrascom.py`\n",
        "**üìå Funci√≥n principal:**\n",
        "\n",
        "Busca URLs de canciones en `letras.com` para aquellas que no pudieron obtenerse con la API.\n",
        "\n",
        "**‚öôÔ∏è ¬øC√≥mo lo hace?**\n",
        "\n",
        "1. Intenta una URL directa generando un slug (formato URL amigable) del artista y la canci√≥n.\n",
        "\n",
        "2. Si falla, hace una b√∫squeda manual:\n",
        "**`https://www.letras.com/buscar/{track_name + artist_name}`**\n",
        "\n",
        "3. Extrae la primera URL v√°lida del resultado de b√∫squeda (`<a class=\"song-name\">`).\n",
        "\n",
        "4. Guarda la URL en urls_letrascom.csv.\n",
        "\n",
        "### ‚úÖ Resultado:\n",
        "Obtiene una buena cantidad de URLs v√°lidas de letras no encontradas anteriormente, que m√°s tarde, podremos usar para hacer scrapling utlizando esta misma p√°gina web.\n",
        "\n",
        "### ‚ö†Ô∏è Errores y ajustes:\n",
        "* Algunos nombres no generaban slugs v√°lidos ‚Üí se cre√≥ funci√≥n slugify.\n",
        "\n",
        "* El scraping directo de los resultados requer√≠a un user-agent realista.\n",
        "\n",
        "* Se evit√≥ Selenium (aunque se valor√≥), ya que:\n",
        "\n",
        "* Aumentaba complejidad.\n",
        "\n",
        "* No era necesario para p√°ginas simples como letras.com.\n",
        "\n",
        "* El HTML pod√≠a manejarse con requests + BeautifulSoup.\n",
        "\n",
        "## üîß C√≥digo 3 ‚Äì `scrapear_letras_letrascom.py`\n",
        "**üìå Funci√≥n principal:**\n",
        "\n",
        "Accede a cada URL obtenida de letras.com y extrae el texto de la letra mediante scrapling.\n",
        "\n",
        "**‚öôÔ∏è ¬øC√≥mo lo hace?**\n",
        "1. Se accede con requests con un `user-agent` personalizado.\n",
        "\n",
        "2. Se usa BeautifulSoup para encontrar el `<div class=\"lyric-original\">`, donde est√° la letra.\n",
        "2.2 Cabe resaltar que probamos con diferentes p√°ginas web para hacer scrapling, pero en el momento de sacar las letras de las URLs de las canciones, no pod√≠amos ya que tenian la clases din√°micas. Esto nos paso con **`Genius`**.\n",
        "\n",
        "3. Se limpian los espacios y se formatea el texto adecuadamente.\n",
        "\n",
        "4. Guarda el resultado en letras_com_scrapeadas_corregido.csv.\n",
        "\n",
        "### ‚ö†Ô∏è Problemas y soluciones:\n",
        "    * Problema\tSoluci√≥n implementada\n",
        "    Algunas letras no estaban en el HTML - Se detect√≥ el mensaje \"letra no disponible\" y se omiti√≥.\n",
        "    HTML din√°mico no cargado\t         - Se descart√≥ usar Selenium por simplicidad y eficiencia.\n",
        "    Dificultades de codificaci√≥n\t     - Se forz√≥ utf-8 y, como fallback, latin-1.\n",
        "    Saltos de l√≠nea perdidos\t         - Se us√≥ .get_text(separator=\"\\n\", strip=True) para conservarlos.\n",
        "\n",
        "### Resultado:\n",
        "Se logr√≥ scrapear la mayor√≠a de las letras restantes de forma efectiva, ampliando el dataset con informaci√≥n valiosa.\n",
        "\n",
        "## üß™ Herramientas Consideradas pero NO utilizadas\n",
        "\n",
        "| Herramienta             | Motivo de descarte                                                                                                                               |\n",
        "|-------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| Selenium                | Se consider√≥ al principio para scrapear `letras.com` en caso de HTML din√°mico. Pero al ser contenido est√°tico y bien estructurado, no era necesario. Adem√°s, Selenium requer√≠a m√°s dependencias, navegador, y era m√°s lento. |\n",
        "| APIs alternativas (Genius, Musixmatch, etc.) | Requieren autenticaci√≥n (API key) y tienen l√≠mites estrictos o cobran. No eran viables para scraping automatizado sin riesgo de bloqueo. |\n",
        "| Scrapy                  | Es potente, pero innecesario para la escala y simplicidad de este scraping. Se opt√≥ por `requests + BeautifulSoup` por ser m√°s ligero.           |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QIkFmhk_jmd_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üé∂ An√°lisis de Letras de Canciones ‚Äì Punto 2: Lenguaje y Estilo\n",
        "\n",
        "Este an√°lisis forma parte de un proyecto de NLP aplicado a letras de canciones. El objetivo del **Punto 2** es estudiar las propiedades ling√º√≠sticas b√°sicas de las letras recopiladas en dos datasets distintos que se unificaron previamente.\n",
        "\n",
        "---\n",
        "\n",
        "## üìÇ Estructura del dataset\n",
        "\n",
        "- **letras_com_scrapeadas_corregido.csv**\n",
        "- **canciones_con_letras.csv**\n",
        "\n",
        "Ambos archivos fueron combinados para formar un solo corpus de letras. Las columnas relevantes fueron:\n",
        "\n",
        "- `track_name`\n",
        "- `artist_name`\n",
        "- `lyrics`\n",
        "\n",
        "---\n",
        "\n",
        "## üßº Preprocesamiento realizado\n",
        "\n",
        "1. Conversi√≥n de texto a min√∫sculas\n",
        "2. Eliminaci√≥n de puntuaci√≥n y s√≠mbolos\n",
        "3. Tokenizaci√≥n por espacios\n",
        "4. Uni√≥n de los datasets\n",
        "\n",
        "---\n",
        "\n",
        "## üîç An√°lisis realizado\n",
        "\n",
        "### 1. Palabras m√°s comunes\n",
        "\n",
        "Se analizaron las 20 palabras m√°s frecuentes en el corpus total de letras. Las m√°s comunes fueron:\n",
        "\n",
        "- **you, i, me, love, know, like**, etc.\n",
        "\n",
        "Estas palabras reflejan el estilo √≠ntimo y emocional de muchas canciones, especialmente en g√©neros como el pop, R&B y baladas.\n",
        "\n",
        "### 2. Riqueza l√©xica\n",
        "\n",
        "Se calcul√≥ como:\n",
        "\n",
        "\n",
        "- Valores bajos indican letras muy repetitivas.\n",
        "- Valores altos indican diversidad de vocabulario.\n",
        "- La mayor√≠a de canciones tienen una riqueza entre **0.2 y 0.5**.\n",
        "\n",
        "### 3. Longitud de las letras\n",
        "\n",
        "- La longitud promedio se encuentra entre **200 y 400 palabras**.\n",
        "- Muchas canciones cortas (<100 palabras) y algunas muy largas (>1000 palabras), lo que sugiere variedad de g√©neros o estilos.\n",
        "\n",
        "---\n",
        "\n",
        "## üìä Visualizaciones generadas\n",
        "\n",
        "- Gr√°fico de barras: top 20 palabras m√°s comunes\n",
        "- Histograma: distribuci√≥n de riqueza l√©xica\n",
        "- Histograma: distribuci√≥n de longitud de las letras\n",
        "\n",
        "---\n",
        "\n",
        "## üìå Conclusiones\n",
        "\n",
        "- Las letras tienen un enfoque personal y emocional.\n",
        "- Predomina un lenguaje informal.\n",
        "- Hay gran variabilidad en longitud y riqueza, lo que sugiere mezcla de g√©neros.\n",
        "\n",
        "---\n",
        "\n",
        "> En la siguiente etapa (Punto 4), se proceder√° a extraer los **t√≥picos o temas comunes** presentes en las letras mediante t√©cnicas de modelado de temas.\n"
      ],
      "metadata": {
        "id": "DOzOxBiFiLDL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# üéµ An√°lisis de T√≥picos en Letras de Canciones por G√©nero Musical ‚Äì Punto 4\n",
        "\n",
        "Este proyecto utiliza t√©cnicas de modelado de t√≥picos (LDA) para analizar las letras de canciones y descubrir patrones tem√°ticos dominantes asociados a distintos g√©neros musicales.\n",
        "\n",
        "## üìå Descripci√≥n\n",
        "\n",
        "Se identificaron 5 t√≥picos dominantes a partir de las letras de canciones utilizando un modelo de LDA y se visualiz√≥ su distribuci√≥n por g√©nero musical mediante un mapa de calor.\n",
        "\n",
        "## üìÅ Estructura del Proyecto\n",
        "\n",
        "- `playlist_con_letras.csv`: Dataset base con informaci√≥n de canciones.\n",
        "- `analisis_lda.py`: Script principal para an√°lisis y visualizaci√≥n.\n",
        "- `memoria.txt`: Documento con interpretaci√≥n detallada y conclusiones del an√°lisis.\n",
        "\n",
        "## üß™ Tecnolog√≠as\n",
        "\n",
        "- Python\n",
        "- Pandas, Numpy, Matplotlib, Seaborn, Scikit-learn, NLTK\n",
        "\n",
        "## üìä Resultados\n",
        "\n",
        "- Asociaci√≥n clara entre ciertos t√≥picos y g√©neros (ej. Trap Latino con tem√°ticas urbanas).\n",
        "- Detecci√≥n de diferencias entre letras en espa√±ol e ingl√©s.\n",
        "- Utilidad para clasificaci√≥n musical, an√°lisis de audiencias y sistemas de recomendaci√≥n.\n",
        "\n",
        "## üìö Referencias\n",
        "\n",
        "- LDA: Latent Dirichlet Allocation (Blei et al., 2003)\n",
        "- Dataset: Letras y g√©neros extra√≠dos desde una playlist de Spotify\n",
        "\n"
      ],
      "metadata": {
        "id": "ANYJFOeSRJm5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üé∂ An√°lisis de Letras de Canciones ‚Äì Punto 6: Frecuencia y Similitud\n",
        "\n",
        "Este proyecto utiliza Python y diversas bibliotecas de an√°lisis de datos y visualizaci√≥n para explorar un conjunto de datos de letras de canciones. Realiza an√°lisis de frecuencia de palabras y calcula la similitud l√©xica entre diferentes canciones y artistas.\n",
        "\n",
        "## Caracter√≠sticas Principales\n",
        "\n",
        "* **An√°lisis de Frecuencia de Palabras:**\n",
        "    * Compara las palabras m√°s utilizadas por un artista angloparlante (Taylor Swift) y un artista hispanohablante (Bad Bunny).\n",
        "    * Analiza la evoluci√≥n de las palabras m√°s frecuentes en las letras de Coldplay a lo largo de dos d√©cadas (2000s vs. 2010s).\n",
        "* **An√°lisis de Similitud de Letras:**\n",
        "    * Calcula y visualiza la similitud (usando TF-IDF y similitud del coseno) entre letras de 10 canciones de artistas diversos.\n",
        "    * Calcula y visualiza la similitud entre letras de canciones pertenecientes a un mismo g√©nero musical (Pop).\n",
        "* **Limpieza de Texto:** Incluye un preprocesamiento de las letras para normalizar el texto, eliminar caracteres no alfab√©ticos y filtrar stopwords en ingl√©s y espa√±ol.\n",
        "\n",
        "## Requisitos Previos\n",
        "\n",
        "* Python 3.x\n",
        "* Las siguientes bibliotecas de Python:\n",
        "    * `pandas`\n",
        "    * `matplotlib`\n",
        "    * `seaborn`\n",
        "    * `scikit-learn`\n",
        "    * `collections` (generalmente viene con Python est√°ndar)\n",
        "    * `re` (generalmente viene con Python est√°ndar)\n",
        "* Un archivo de datos llamado `playlist_con_letras.csv` en el mismo directorio que el script.\n",
        "\n",
        "## Estructura del Archivo de Datos (`playlist_con_letras.csv`)\n",
        "\n",
        "El archivo CSV debe contener al menos las siguientes columnas:\n",
        "\n",
        "* `artist_name`: Nombre del artista.\n",
        "* `track_name`: Nombre de la canci√≥n.\n",
        "* `lyrics`: Letra de la canci√≥n.\n",
        "* `year`: A√±o de lanzamiento de la canci√≥n (para el an√°lisis de Coldplay).\n",
        "\n",
        "## Instalaci√≥n\n",
        "\n",
        "1.  Aseg√∫rate de tener Python 3 instalado.\n",
        "2.  Clona este repositorio o descarga los archivos.\n",
        "3.  Instala las bibliotecas necesarias. Puedes hacerlo usando pip:\n",
        "\n",
        "    ```bash\n",
        "    pip install pandas matplotlib seaborn scikit-learn\n",
        "    ```\n",
        "\n",
        "## Uso\n",
        "\n",
        "1.  Coloca tu archivo `playlist_con_letras.csv` en el mismo directorio que el script de Python.\n",
        "2.  Ejecuta el script desde tu terminal:\n",
        "\n",
        "    ```bash\n",
        "    python tu_script.py\n",
        "    ```\n",
        "\n",
        "    (Reemplaza `tu_script.py` con el nombre real de tu archivo Python).\n",
        "\n",
        "3.  El script generar√° y mostrar√° varios gr√°ficos como salida.\n",
        "\n",
        "### Salidas Esperadas (Visualizaciones)\n",
        "\n",
        "A continuaci√≥n se describe qu√© gr√°ficos se generan y d√≥nde ir√≠an las im√°genes si las a√±adieras a este README.\n",
        "\n",
        "1.  **An√°lisis de Frecuencia: Taylor Swift vs. Bad Bunny**\n",
        "    * Descripci√≥n: Dos diagramas de barras mostrando las 15 palabras m√°s frecuentes para Taylor Swift y Bad Bunny, respectivamente, despu√©s de la limpieza y eliminaci√≥n de stopwords.\n",
        "    * *Aqu√≠ podr√≠as insertar una imagen del gr√°fico:*\n",
        "        `![Frecuencia de Palabras: Taylor Swift vs. Bad Bunny](ruta/a/imagen_frecuencia_taylor_badbunny.png)`\n",
        "\n",
        "2.  **An√°lisis de Frecuencia: Coldplay por D√©cadas**\n",
        "    * Descripci√≥n: Dos diagramas de barras mostrando las 15 palabras m√°s frecuentes en las canciones de Coldplay de la d√©cada de 2000 y la d√©cada de 2010.\n",
        "    * *Aqu√≠ podr√≠as insertar una imagen del gr√°fico:*\n",
        "        `![Frecuencia de Palabras: Coldplay 2000s vs 2010s](ruta/a/imagen_frecuencia_coldplay_decadas.png)`\n",
        "\n",
        "3.  **Similitud entre Letras (Artistas Diferentes)**\n",
        "    * Descripci√≥n: Un mapa de calor (heatmap) que muestra la similitud del coseno entre las letras de 10 canciones seleccionadas aleatoriamente de artistas diferentes.\n",
        "    * *Aqu√≠ podr√≠as insertar una imagen del heatmap:*\n",
        "        `![Similitud Letras: Artistas Diversos](ruta/a/imagen_similitud_diversos.png)`\n",
        "\n",
        "4.  **Similitud entre Letras (Mismo G√©nero - Pop)**\n",
        "    * Descripci√≥n: Un mapa de calor (heatmap) que muestra la similitud del coseno entre las letras de varias canciones seleccionadas del g√©nero Pop.\n",
        "    * *Aqu√≠ podr√≠as insertar una imagen del heatmap:*\n",
        "        `![Similitud Letras: G√©nero Pop](ruta/a/imagen_similitud_pop.png)`\n",
        "\n",
        "## Personalizaci√≥n\n",
        "\n",
        "* **Artistas para An√°lisis de Frecuencia:** Puedes cambiar los artistas en la lista `artists_to_compare` en la secci√≥n 1 del script.\n",
        "* **Artistas para An√°lisis de G√©nero:** Modifica la lista `pop_artists_list` en la secci√≥n 4 para incluir diferentes artistas del g√©nero que desees analizar, o cambia el g√©nero por completo.\n",
        "* **N√∫mero de Palabras/Canciones:** Ajusta el n√∫mero de palabras m√°s comunes (`most_common(15)`) o el n√∫mero de canciones en las muestras (`sample(10)`) seg√∫n tus necesidades.\n",
        "* **Stopwords:** Puedes expandir las listas `basic_stopwords_en` y `basic_stopwords_es` si identificas m√°s palabras comunes que deseas excluir del an√°lisis.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "aDVBxMNCM11p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üé∂ An√°lisis de Letras de Canciones ‚Äì Punto 7: Tendencias y Contexto Social\n",
        "\n",
        "Este an√°lisis forma parte de un proyecto de NLP aplicado a letras de canciones. El **Punto 7** examina c√≥mo eventos sociales relevantes (como la pandemia de COVID-19) y factores ling√º√≠sticos (idioma del artista) se reflejan en el contenido l√≠rico.\n",
        "\n",
        "---\n",
        "\n",
        "## üìÇ Estructura del Dataset\n",
        "\n",
        "- `playlist_con_letras.csv`\n",
        "\n",
        "Columnas clave:\n",
        "- `artist_name`: Nombre del artista\n",
        "- `track_name`: Nombre de la canci√≥n\n",
        "- `lyrics`: Letra completa\n",
        "- `year`: A√±o de lanzamiento\n",
        "\n",
        "---\n",
        "\n",
        "## üßº Preprocesamiento realizado\n",
        "\n",
        "1. Conversi√≥n a min√∫sculas  \n",
        "2. Eliminaci√≥n de signos de puntuaci√≥n y caracteres no alfab√©ticos  \n",
        "3. Normalizaci√≥n de contracciones  \n",
        "4. Tokenizaci√≥n  \n",
        "5. Eliminaci√≥n de stopwords (en ingl√©s y espa√±ol)\n",
        "\n",
        "---\n",
        "\n",
        "## üîç An√°lisis realizado\n",
        "\n",
        "### 1. Impacto de la Pandemia de COVID-19 ü¶†\n",
        "\n",
        "Comparativa de frecuencia relativa de palabras clave entre dos periodos:\n",
        "\n",
        "- **Antes de la pandemia**: 2017‚Äì2019  \n",
        "- **Durante la pandemia**: 2020‚Äì2022\n",
        "\n",
        "üìå Hallazgos principales:\n",
        "- **Incremento notorio** de t√©rminos como: `virus`, `covid`, `pandemia`, `mascarilla`, `confinamiento`, `distancia`.\n",
        "- **Temas emocionales y personales** m√°s presentes: `casa`, `solo`, `miedo`, `salud`, `esperanza`.\n",
        "- **Mayor expresi√≥n en espa√±ol** para t√©rminos sanitarios, como `mascarilla` y `confinamiento`.\n",
        "\n",
        "üìä Visualizaci√≥n:\n",
        "- Gr√°fico de barras de frecuencias relativas (ej. `image_c58441.png`)  \n",
        "  `![Impacto de la Pandemia en Letras](ruta/a/tu/image_c58441.png)`\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Comparativa Ling√º√≠stica: Hispanohablantes vs. Angloparlantes üó£Ô∏è\n",
        "\n",
        "An√°lisis basado en la agrupaci√≥n manual de artistas seg√∫n idioma predominante.\n",
        "\n",
        "üìå Hallazgos principales:\n",
        "\n",
        "- **Code-switching** en artistas hispanohablantes:  \n",
        "  Palabras como `baby`, `like`, `love`, `one`, `theres` aparecen con alta frecuencia en letras en espa√±ol.\n",
        "\n",
        "- **Vocabularios representativos**:  \n",
        "  - **Angloparlantes**: `like`, `love`, `got`, `baby`, `time`, `never`, `ooh`  \n",
        "  - **Hispanohablantes**: `quiero`, `bien`, `dura`, `contigo`, `mami`, `coraz√≥n`, `noche`, `uoh`\n",
        "\n",
        "- **Diferencia en tama√±o de corpus**:  \n",
        "  El corpus en ingl√©s fue notablemente m√°s grande que el de espa√±ol, lo que puede influir en la diversidad l√©xica observada.\n",
        "\n",
        "---\n",
        "\n",
        "## üß™ Metodolog√≠a\n",
        "\n",
        "- Herramientas utilizadas:\n",
        "  - `Python`, `Pandas`, `NLTK`, `Matplotlib`, `Seaborn`\n",
        "- T√©cnicas:\n",
        "  - C√°lculo de frecuencias relativas (por cada 10,000 palabras)\n",
        "  - Extracci√≥n de n-gramas\n",
        "  - Visualizaci√≥n comparativa por periodo o grupo\n",
        "\n",
        "---\n",
        "\n",
        "## üìå Conclusiones\n",
        "\n",
        "- Las letras reflejan cambios sociales importantes: la pandemia se manifiesta expl√≠citamente en el lenguaje.\n",
        "- El **code-switching** (uso de ingl√©s en letras en espa√±ol) es com√∫n entre artistas hispanos contempor√°neos.\n",
        "- A pesar de diferencias culturales y ling√º√≠sticas, **temas universales como el amor** siguen predominando en ambos grupos.\n",
        "- El an√°lisis de letras musicales ofrece una ventana cuantitativa a **tendencias culturales y sociales** en la m√∫sica popular.\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4jOhh8jD-o9Z"
      }
    }
  ]
}